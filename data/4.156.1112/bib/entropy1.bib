@MISC{ENTROPY1.MIZ,
  AUTHOR = {Zhang, Bo and Nakamura, Yatsuka},
  TITLE = {Definition and Some Properties of Information Entropy},
  DAY = {9},
  MONTH = {July},
  YEAR = {2007},
  ADDRESS1 = {Shinshu University, Nagano, Japan},
  ADDRESS2 = {Shinshu University, Nagano, Japan},
  SECTION1 = {Preliminaries},
  SECTION2 = {Properties of Transformations between Vector and Matrix},  
  SECTION3 = {Information Entropy},
  SUMMARY = {In this article, we mainly define the information entropy
  \cite{Billingsley:1964}, \cite{Hirasawa:1996} and
    prove some basic properties of it.
    First, we discuss some properties on four kinds of transformation functions
    between vector and matrix. The transformation functions are LineVec2Mx,
    ColVec2Mx, Vec2DiagMx and Mx2Fins. Mx2FinS is a horizontal concatenation
    operator for a given matrix, treating rows of the given matrix as finite
    sequences, yielding a new finite sequence by horizontally joining the each
    row of the given matrix in order to index.
    Then we define each concept of information entropy for a probability
    sequence and two kinds of probability matrices, joint and conditional, that
    are defined in article \cite{MATRPROB.ABS}.
    Further, we discuss some properties of information entropy including
    Shannon's lemma, maximum property, additivity and super-additivity
    properties.}}

@BOOK{Billingsley:1964,
 AUTHOR={Billingsley, P.},
 TITLE={Ergodic Theory and Information},
 PUBLISHER={John Wiley & Sons},
 YEAR=1964}

@BOOK{Hirasawa:1996,
 AUTHOR={Hirasawa, Shigeichi},
 TITLE={Information Theory},
 PUBLISHER={Baifukan CO.},
 YEAR=1996}
